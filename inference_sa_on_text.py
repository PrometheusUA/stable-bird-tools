birdset_ID2CLASS = [
    "gretit1",
    "eurbla",
    "comcha",
    "comchi1",
    "eurrob1",
    "sonthr1",
    "blackc1",
    "blutit",
    "redcro",
    "winwre4",
    "coatit2",
    "houspa",
    "grswoo",
    "comnig1",
    "dunnoc1",
    "skylar",
    "comrav",
    "eurgre1",
    "eurgol",
    "trepip",
    "eurnut2",
    "eurjay1",
    "houwre",
    "eursta",
    "cetwar1",
    "barswa",
    "eurlin1",
    "lottit1",
    "carcro1",
    "martit2",
    "eurbul",
    "sarwar1",
    "eugori2",
    "spofly1",
    "sonspa",
    "shttre1",
    "firecr1",
    "eurmag1",
    "eurser1",
    "mallar3",
    "woolar1",
    "cretit2",
    "eucdov",
    "zitcis1",
    "spotow",
    "bcnher",
    "cirbun1",
    "bewwre",
    "rewbla",
    "rucspa1",
    "norcar",
    "combuz1",
    "grywag",
    "cowpig1",
    "amerob",
    "melwar1",
    "swathr",
    "comyel",
    "grekis",
    "daejun",
    "carwre",
    "warvir",
    "eurwry",
    "roahaw",
    "cangoo",
    "banana",
    "gretin1",
    "cintin1",
    "littin1",
    "undtin1",
    "bartin2",
    "horscr1",
    "hawgoo",
    "snogoo",
    "tunswa",
    "wooduc",
    "grhcha1",
    "specha3",
    "colcha1",
    "spigua1",
    "mouqua",
    "calqua",
    "stwqua1",
    "wiltur",
    "kalphe",
    "blkfra",
    "chukar",
    "ercfra",
    "compau",
    "compot1",
    "annhum",
    "buvhum1",
    "stvhum2",
    "rtlhum",
    "andeme1",
    "strcuc1",
    "squcuc1",
    "yebcuc",
    "scapig2",
    "batpig1",
    "pavpig2",
    "rebpig1",
    "plupig2",
    "rudpig",
    "eutdov",
    "blgdov1",
    "ruqdov",
    "whtdov",
    "grfdov1",
    "moudov",
    "gycwor1",
    "amgplo",
    "killde",
    "amewoo",
    "sposan",
    "solsan",
    "ribgul",
    "barpet",
    "hawpet1",
    "greibi1",
    "grbher3",
    "coohaw",
    "gryhaw2",
    "reshaw",
    "hawhaw",
    "amapyo1",
    "fepowl",
    "trsowl",
    "tabsco1",
    "brdowl",
    "blttro1",
    "gnbtro1",
    "viotro3",
    "blctro1",
    "coltro1",
    "garkin1",
    "rinkin1",
    "belkin1",
    "bucmot2",
    "bucmot4",
    "higmot1",
    "blfjac1",
    "wespuf1",
    "blfnun1",
    "gilbar1",
    "letbar1",
    "rehbar1",
    "kebtou1",
    "whttou1",
    "acowoo",
    "yetwoo2",
    "hofwoo1",
    "rebwoo",
    "wilsap",
    "yebsap",
    "dowwoo",
    "litwoo2",
    "haiwoo",
    "whhwoo",
    "whtwoo2",
    "gogwoo1",
    "norfli",
    "scbwoo5",
    "rinwoo1",
    "linwoo1",
    "pilwoo",
    "renwoo1",
    "blacar1",
    "yehcar1",
    "laufal1",
    "baffal1",
    "coffal1",
    "buffal1",
    "orcpar",
    "cowpar1",
    "blhpar1",
    "whcpar",
    "brwpar1",
    "whfpar1",
    "meapar",
    "orfpar",
    "duhpar",
    "rebmac2",
    "crfpar",
    "oliwoo1",
    "plbwoo1",
    "citwoo1",
    "lobwoo1",
    "amabaw1",
    "strwoo2",
    "elewoo1",
    "butwoo1",
    "stbwoo2",
    "sthwoo1",
    "strxen1",
    "crfgle1",
    "chwfog1",
    "btfgle1",
    "azaspi1",
    "spwant2",
    "bltant2",
    "pygant1",
    "whfant2",
    "lowant1",
    "gryant1",
    "pltant1",
    "dutant2",
    "barant1",
    "plwant1",
    "fasant1",
    "greant1",
    "bsbeye1",
    "gryant2",
    "pluant1",
    "goeant1",
    "rucant2",
    "blfant1",
    "rufant3",
    "astgna1",
    "wibpip1",
    "yectyr1",
    "forela1",
    "yebela1",
    "whltyr1",
    "rinant2",
    "goftyr1",
    "whbtot1",
    "ruftof1",
    "cotfly1",
    "yemfly1",
    "gycfly1",
    "gocspa1",
    "whcspa1",
    "eulfly1",
    "easpho",
    "olsfly",
    "wewpew",
    "eawpew",
    "aldfly",
    "hamfly",
    "dusfly",
    "pasfly",
    "pirfly1",
    "rumfly1",
    "socfly1",
    "grcfly1",
    "bobfly1",
    "trokin",
    "easkin",
    "gramou1",
    "whrsir1",
    "ducfly",
    "grcfly",
    "ducatt1",
    "brratt1",
    "putfru1",
    "scrpih1",
    "blfcot1",
    "lotman1",
    "batman1",
    "royfly1",
    "mastit1",
    "cinmou1",
    "whwbec1",
    "blcbec1",
    "rotbec",
    "ducgre1",
    "reevir1",
    "hutvir",
    "yetvir",
    "buhvir",
    "casvir",
    "elepai",
    "blcjay1",
    "grnjay",
    "brnjay",
    "blujay",
    "stejay",
    "clanut",
    "amegfi",
    "pinsis",
    "puteup1",
    "yeceup1",
    "yeteup1",
    "blbthr1",
    "whnrob1",
    "hauthr1",
    "clcrob",
    "bubwre1",
    "muswre2",
    "melbla1",
    "rusbla",
    "brebla",
    "comgra",
    "grtgra",
    "ovenbi1",
    "louwat",
    "norwat",
    "buwwar",
    "bawwar",
    "tenwar",
    "orcwar",
    "naswar",
    "macwar",
    "kenwar",
    "hoowar",
    "amered",
    "babwar",
    "bkbwar",
    "yelwar",
    "chswar",
    "yerwar",
    "btywar",
    "towwar",
    "herwar",
    "thelar1",
    "crelar1",
    "btnwar",
    "rucwar1",
    "rucwar",
    "wlswar",
    "sltred",
    "scatan",
    "westan",
    "rcatan1",
    "robgro",
    "bkhgro",
    "bubgro2",
    "lazbun",
    "bugtan",
    "blctan1",
    "scrtan1",
    "partan1",
    "woothr",
    "obnthr1",
    "herthr",
    "veery",
    "evegro",
    "strsal1",
    "sibtan2",
    "buggna",
    "whbnut",
    "rebnut",
    "brncre",
    "grycat",
    "rocpet1",
    "comwax",
    "easwar1",
    "darwar1",
    "tuftit",
    "chbchi",
    "bkcchi",
    "mouchi",
    "amepip",
    "gcrfin",
    "palila",
    "iiwi",
    "apapan",
    "hawcre",
    "akepa1",
    "hawama",
    "purfin",
    "casfin",
    "houfin",
    "wegspa1",
    "pregrs2",
    "gnttow",
    "eastow",
    "boboli",
    "ruboro1",
    "olioro1",
    "monoro1",
    "sobcac1",
    "yercac1",
    "yebori1",
    "balori",
    "bnhcow",
    "ruckin",
    "gockin",
    "runwre1",
    "thlwre1",
    "rocwre",
    "whiwre1",
    "rubwre1",
    "rawwre1",
    "plawre1",
    "moublu",
    "easblu",
    "towsol",
    "omao",
    "andsol1",
    "warwhe1",
    "ccbfin",
    "foxspa",
    "whcspa",
    "whtspa",
    "vesspa",
    "linspa",
    "swaspa",
    "treswa",
    "jabwar",
    "grasal3",
    "butsal1",
    "blhsal1",
    "yefgra1",
    "flrtan1",
    "amecro",
    "cedwax",
    "yefcan",
    # "reblei",
    # "melthr"
]

rare_ID2CLASS = ['blchaw1', 'bobher1', 'neocor', 'palhor2', 'bicwre1', 'brtpar1', 'olipic1', 'yelori1', 'piwtyr1', 'grepot1', 'crbtan1', 'labter1', 'shghum1', 'rufmot1', 'sahpar1', 'woosto', 'royfly1', 'bubcur1', 'rutpuf1', 'whmtyr1', 'amakin1', 'rubsee1', 'plctan1', 'cregua1', 'yectyr1', 'blkvul', 'yehbla2', 'recwoo1', 'grasal4', 'spepar1', 'cinbec1', 'fotfly', 'ampkin1', 'piepuf1', 'crebob1', 'shtfly1', 'bucmot3', 'blctit1', 'plukit1', 'cocher1', 'cargra1', 'tbsfin1', 'anhing', 'rebbla1', 'whwswa1', 'thlsch3', 'spbwoo1', 'verfly', 'rosspo1', 'savhaw1', 'ruther1', 'grysee1', 'turvul', 'norscr1', 'bafibi1', 'gretin1', 'colara1', 'ragmac1', 'whttro1']

taxonomy_path = '/home/jovyan/data/eBird_Taxonomy_v2021.csv'
classes_descriptions_path = '/home/jovyan/classes_descriptions_birdclef.csv'


import os
import json
from itertools import chain
from glob import glob

import torch
import soundfile as sf
import numpy as np
import pandas as pd
import librosa

from tqdm import tqdm
from stable_audio_tools.interface.gradio import load_model
from stable_audio_tools.inference.generation import generate_diffusion_cond


# taxonomy_df = pd.read_csv(taxonomy_path)
classes_descs_df = pd.read_csv(classes_descriptions_path)
print(f"Loaded {len(classes_descs_df)} descriptions")

for STEPS, CFG_SCALE in [(50, 6)]:
    CONFIG_PATH = '/home/jovyan/stable-bird-tools/stablebird_model_textprompt_finetune_config.json'
    CKPT_PATH = '/home/jovyan/stable-bird-tools/stablebird_text_2500_after500.ckpt'
    OUT_PATH = f'/home/jovyan/samples/stablebird_text_2500_after500_cfg{CFG_SCALE}_{STEPS}steps_rare/'
    SAMPLES_PERCLASS = 50
    CLASSES_BATCH = 5
    ID2CLASS = rare_ID2CLASS
    USE_INIT_AUDIO=False
    INIT_AUDIOS_PATH='/home/jovyan/data/datasets/birdclef_rare/train'
    INIT_AUDIO_APPROACH='classes_dict'  # one of {'random_other', 'classes_dict'}
    CLASSES_DICT_PATH = '/home/jovyan/rare_species_close.json'

    init_audios = []

    with open(CONFIG_PATH) as f:
        model_config = json.load(f)
    model, model_config = load_model(model_config=model_config, 
                                    model_ckpt_path=CKPT_PATH, 
                                    device="cuda", model_half=True)

    if USE_INIT_AUDIO:
        init_audios = glob(os.path.join(INIT_AUDIOS_PATH, '*/*.wav'))
        print(f"Found {len(init_audios)} possible audios for init")

    if USE_INIT_AUDIO and len(init_audios) > 0:
        raise NotImplementedError("init audio not ready for text inference")
        if INIT_AUDIO_APPROACH == 'classes_dict':
            assert os.path.exists(CLASSES_DICT_PATH)

            with open(CLASSES_DICT_PATH, 'r') as f:
                close_classes_dict = json.load(f)

        for class_id in tqdm(range(0, len(ID2CLASS)), desc='Audio classes'):
            classname = ID2CLASS[class_id]
            out_folder = os.path.join(OUT_PATH, classname)
            os.makedirs(out_folder, exist_ok=True)

            init_audio_paths = None
            if INIT_AUDIO_APPROACH == 'random_other':
                other_class_samples = [audiopath for audiopath in init_audios if classname not in audiopath]
                init_audio_paths = np.random.choice(other_class_samples, size=SAMPLES_PERCLASS)
            elif INIT_AUDIO_APPROACH == 'classes_dict':
                valid_classes = close_classes_dict[classname]
                other_class_samples = [audiopath for audiopath in init_audios if any([check_classname in audiopath for check_classname in valid_classes])]
                init_audio_paths = np.random.choice(other_class_samples, size=SAMPLES_PERCLASS)
            else:
                raise NotImplementedError()

            for audio_i, init_audio_path in enumerate(init_audio_paths):
                init_audio, sr = librosa.load(init_audio_path, sr=44100)
                if init_audio.ndim == 1:
                    init_audio = init_audio[None, :]
                init_audio = torch.tensor(init_audio, dtype=torch.float16)

                gen = generate_diffusion_cond(model, 
                    steps = STEPS,
                    cfg_scale=CFG_SCALE,
                    conditioning = [{"class": class_id, "seconds_start": 0, "seconds_total": 10.}],
                    batch_size = 1,
                    sample_size=441000,
                    sample_rate=44100,
                    seed = -1,
                    device = "cuda",
                    init_audio = (sr, init_audio),
                    return_latents = False,
                )

                generated_audio = gen[0].cpu().numpy().astype(np.float32)
                sf.write(os.path.join(out_folder, f"{audio_i}.wav"), generated_audio.T, 44100)

    else:
        for start_class_id in tqdm(range(0, len(ID2CLASS), CLASSES_BATCH), desc='Audio classes batch'):
            classnames = ID2CLASS[start_class_id:start_class_id+CLASSES_BATCH]

            last_species_dir = os.path.join(OUT_PATH, classnames[-1])
            if os.path.exists(last_species_dir) and (len(os.listdir(last_species_dir)) >= SAMPLES_PERCLASS):
                print(f"Skipping batch because all is generated already")
                continue

            conditioning_dicts = []
            for class_id in range(start_class_id, min(start_class_id + CLASSES_BATCH, len(ID2CLASS))):
                classname = classnames[class_id - start_class_id]
                specie_prompts_df = classes_descs_df.loc[classes_descs_df['specie'] == classname, 'response']
                conditioning_dicts.extend([{
                    "prompt": specie_prompts_df.sample().iloc[0],
                    "seconds_start": 0, 
                    "seconds_total": 10.
                } for _ in range(SAMPLES_PERCLASS)])

            gen = generate_diffusion_cond(model, 
                    steps = STEPS,
                    cfg_scale=CFG_SCALE,
                    conditioning = conditioning_dicts,  # [sample_dict for class_id in range(start_class_id, min(start_class_id + CLASSES_BATCH, len(ID2CLASS))) for sample_dict in ([{"class": class_id, "seconds_start": 0, "seconds_total": 10.}] * SAMPLES_PERCLASS)],
                    batch_size = SAMPLES_PERCLASS*len(classnames),
                    sample_size=441000,
                    sample_rate=44100,
                    seed = -1,
                    device = "cuda",
                    return_latents = False,
            )

            for class_id in range(start_class_id, min(start_class_id + CLASSES_BATCH, len(ID2CLASS))):
                class_id_shift = class_id - start_class_id
                audio_id_shift = class_id_shift * SAMPLES_PERCLASS
                classname = classnames[class_id_shift]
                out_folder = os.path.join(OUT_PATH, classname)
                os.makedirs(out_folder, exist_ok=True)
                for audio_i in range(SAMPLES_PERCLASS):
                    generated_audio = gen[audio_i + audio_id_shift].cpu().numpy().astype(np.float32)
                    sf.write(os.path.join(out_folder, f"{audio_i}.wav"), generated_audio.T, 44100)
